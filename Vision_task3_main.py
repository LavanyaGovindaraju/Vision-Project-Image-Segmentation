# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cofa2FjyDtb6ka55CHVvLoHIpLUFq_YO
"""

import torch
import imageio
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
from PIL import Image
from tqdm import tqdm
from torch.utils import data
from torchvision import transforms
from network3 import *
import torchvision
from torch.utils.data import Dataset, DataLoader

torch.cuda.set_device(7)

dataset = torchvision.datasets.Cityscapes('./cityscapes', split='train', mode='fine',
                     target_type='semantic', transform= transforms.Compose([transforms.ToTensor(), transforms.Resize((512,256)), 
                     transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]),
                     target_transform= transforms.Compose([transforms.ToTensor(), transforms.Resize((512,256))]))

data_loader = torch.utils.data.DataLoader(dataset, batch_size=3, shuffle= True)


net= AttU_Net(img_ch=3,output_ch=34,t=2).cuda()

import torch.optim as optim
# loss function
loss_f = nn.CrossEntropyLoss()

# optimizer variable
opt = optim.Adam(net.parameters(), lr=0.000001, weight_decay=0.0005)

epochs=20
for e in range(epochs):
  for i, d in enumerate(data_loader):
    # your code goes here
    image= d[0]
    mask= d[1]
    image=(image*255).cuda()
    mask=(mask*255).long().reshape(mask.size()[0],512,256).cuda()
    prediction= net.forward(image)
    loss= loss_f(prediction,mask)
    loss.backward()
    opt.step()
    opt.zero_grad()
    if i % 10 == 0:
      print("epoch{}, iter{}, loss: {}".format(e,i,loss.data))
  torch.save(net.state_dict, 'epoch-{}'.format(e))


PATH= " "
torch.save(net, PATH)

